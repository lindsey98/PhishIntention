{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.siamese import *\n",
    "import torch.utils.data as data\n",
    "from PIL import Image, ImageOps\n",
    "import pickle\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create croppped logo for sampled 1000 phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = '/home/l/liny/ruofan/phishpedia/benchmark/Sampled_phish1000/'\n",
    "# annot_file = '/home/l/liny/ruofan/phishpedia/benchmark/phish1000_coord.txt'\n",
    "# os.makedirs('/home/l/liny/ruofan/phishpedia/benchmark/Sample_phish1000_crop', exist_ok=True)\n",
    "\n",
    "# for brand in os.listdir(data_folder):\n",
    "#     img = Image.open(data_folder + brand + '/shot.png')\n",
    "\n",
    "#     ## get ground-truth \n",
    "#     with open(annot_file, 'r') as annotation_file:\n",
    "#         for num, line in enumerate(annotation_file):\n",
    "#             annotation = line.strip().split(',')\n",
    "#             site = ','.join(annotation[:-4])\n",
    "#             if site == brand:\n",
    "#                 bbox_data_gt = np.array(list(annotation[-4:]))\n",
    "#                 if len(bbox_data_gt) != 0:\n",
    "#                     bboxes_gt = bbox_data_gt[:4]\n",
    "#                     x_min_gt, y_min_gt, x_max_gt, y_max_gt = list(map(float, bboxes_gt))\n",
    "#                     gt_bbox = [x_min_gt, y_min_gt, x_max_gt, y_max_gt]\n",
    "#                     break   \n",
    "# #     print(gt_bbox)\n",
    "#     cropped = img.crop((x_min_gt, y_min_gt, x_max_gt, y_max_gt))\n",
    "#     cropped.save(os.path.join('/home/l/liny/ruofan/phishpedia/benchmark/Sample_phish1000_crop', brand+'.png'))\n",
    "#     del gt_bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = '/home/l/liny/ruofan/phishpedia/benchmark/Sample_benign1000/'\n",
    "# annot_file = '/home/l/liny/ruofan/phishpedia/benchmark/benign1000_coord.txt'\n",
    "# os.makedirs('/home/l/liny/ruofan/phishpedia/benchmark/Sample_benign1000_crop', exist_ok=True)\n",
    "\n",
    "# for brand in os.listdir(data_folder):\n",
    "#     img = Image.open(data_folder + brand + '/shot.png')\n",
    "\n",
    "#     ## get ground-truth \n",
    "#     with open(annot_file, 'r') as annotation_file:\n",
    "#         for num, line in enumerate(annotation_file):\n",
    "#             annotation = line.strip().split(',')\n",
    "#             site = ','.join(annotation[:-4])\n",
    "#             if site == brand:\n",
    "#                 bbox_data_gt = np.array(list(annotation[-4:]))\n",
    "#                 if len(bbox_data_gt) != 0:\n",
    "#                     bboxes_gt = bbox_data_gt[:4]\n",
    "#                     x_min_gt, y_min_gt, x_max_gt, y_max_gt = list(map(float, bboxes_gt))\n",
    "#                     gt_bbox = [x_min_gt, y_min_gt, x_max_gt, y_max_gt]\n",
    "#                     break   \n",
    "# #     print(gt_bbox)\n",
    "#     cropped = img.crop((x_min_gt, y_min_gt, x_max_gt, y_max_gt))\n",
    "#     cropped.save(os.path.join('/home/l/liny/ruofan/phishpedia/benchmark/Sample_benign1000_crop', brand+'.png'))\n",
    "#     del gt_bbox\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetLoader(data.Dataset):\n",
    "    def __init__(self, data_root, label_dict, transform=None, grayscale=False):\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.data_root = data_root\n",
    "        self.grayscale = grayscale\n",
    "\n",
    "        with open(label_dict, 'rb') as handle:\n",
    "            self.label_dict = pickle.load(handle)\n",
    "\n",
    "        self.classes = list(self.label_dict.keys())\n",
    "\n",
    "        self.n_data = len(os.listdir(self.data_root))\n",
    "\n",
    "        self.img_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for data in os.listdir(self.data_root):\n",
    "            image_path = data\n",
    "            label = image_path.split('+')[0]\n",
    "            \n",
    "            if brand_converter(label) == 'Microsoft':\n",
    "                self.labels.append(label)\n",
    "                \n",
    "            elif brand_converter(label) == 'DHL Airways':\n",
    "                self.labels.append('DHL')\n",
    "                \n",
    "            elif brand_converter(label) == 'DGI French Tax Authority':\n",
    "                self.labels.append('DGI (French Tax Authority)')\n",
    "                \n",
    "            else:\n",
    "                self.labels.append(brand_converter(label))\n",
    "\n",
    "            self.img_paths.append(image_path)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        img_path, label= self.img_paths[item], self.labels[item]\n",
    "        img_path_full = os.path.join(self.data_root, img_path)\n",
    "        \n",
    "        if self.grayscale:\n",
    "            img = Image.open(img_path_full).convert('L').convert('RGB')\n",
    "        else:\n",
    "            img = Image.open(img_path_full).convert('RGB')\n",
    "\n",
    "        img = ImageOps.expand(img, (\n",
    "            (max(img.size) - img.size[0]) // 2, (max(img.size) - img.size[1]) // 2,\n",
    "            (max(img.size) - img.size[0]) // 2, (max(img.size) - img.size[1]) // 2), fill=(255, 255, 255))\n",
    "\n",
    "        # label = np.array(label,dtype='float32')\n",
    "        label = self.label_dict[label]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.5, 0.5, 0.5]\n",
    "std = [0.5, 0.5, 0.5]\n",
    "\n",
    "img_transforms = transforms.Compose(\n",
    "    [transforms.Resize((95, 95)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=mean, std=std),\n",
    "    ])\n",
    "\n",
    "valid_set = GetLoader(data_root='/home/l/liny/ruofan/phishpedia/benchmark/Sample_phish1000_crop/', \n",
    "                    label_dict='/home/l/liny/ruofan/PhishIntention/src/siamese_retrain/target_dict.json',\n",
    "                     transform=img_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/l/liny/ruofan/PhishIntention/src/siamese_retrain/target_dict.json', 'rb') as handle:\n",
    "    label_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_loader = torch.utils.data.DataLoader(\n",
    "#   valid_set, batch_size=128, shuffle=False, pin_memory=True, drop_last=False)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "  valid_set, batch_size=1, shuffle=False, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_acc(dataloader, model, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for b, (x, y) in tqdm(enumerate(dataloader)):\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            logits = model(x)\n",
    "            pred_cls = torch.argmax(logits, dim=1)\n",
    "\n",
    "            correct += torch.sum(torch.eq(pred_cls, y)).item()\n",
    "            total += y.shape[0]\n",
    "            \n",
    "    print('Accuracy after changing relu function: {:.2f}'.format(correct/total))    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load model (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV2(\n",
       "  (root): Sequential(\n",
       "    (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (pad): ConstantPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (block1): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit04): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit04): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit05): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit06): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (gn): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avg): AdaptiveAvgPool2d(output_size=1)\n",
       "    (conv): Conv2d(2048, 277, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize model\n",
    "model = KNOWN_MODELS[\"BiT-M-R50x1\"](head_size=277, zero_head=True)\n",
    "\n",
    "# Load weights\n",
    "checkpoint = torch.load('/home/l/liny/ruofan/PhishIntention/src/phishpedia/resnetv2_rgb_new.pth.tar', \n",
    "                        map_location=\"cpu\")[\"model\"]\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [01:38, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after changing relu function: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.907"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_acc(valid_loader, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model (change activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizeRelu(nn.Module):\n",
    "    def __init__(self, step_size = 0.01):\n",
    "        super().__init__()\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = torch.ge(x, 0).bool() # mask for positive values\n",
    "        quantize = torch.ones_like(x) * self.step_size\n",
    "        out = torch.mul(torch.floor(torch.div(x, quantize)), self.step_size) # quantize by step_size\n",
    "        out = torch.mul(out, mask) # zero-out negative values\n",
    "        out = torch.abs(out) # remove sign\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV2(\n",
       "  (root): Sequential(\n",
       "    (conv): StdConv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (pad): ConstantPad2d(padding=(1, 1, 1, 1), value=0)\n",
       "    (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (block1): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit04): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): StdConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit04): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit05): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit06): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): Sequential(\n",
       "      (unit01): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): QuantizeRelu()\n",
       "        (downsample): StdConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (unit02): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): QuantizeRelu()\n",
       "      )\n",
       "      (unit03): PreActBottleneck(\n",
       "        (gn1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "        (conv1): StdConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (gn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv2): StdConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (gn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv3): StdConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu): QuantizeRelu()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (gn): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (avg): AdaptiveAvgPool2d(output_size=1)\n",
       "    (conv): Conv2d(2048, 180, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize model\n",
    "model = KNOWN_MODELS[\"BiT-M-R50x1\"](head_size=180, zero_head=True)\n",
    "# Load weights\n",
    "model.load_state_dict(torch.load('/home/l/liny/ruofan/phishpedia/siamese/checkpoints/resnetv2_rgb.pth', map_location=device))\n",
    "\n",
    "# replace relu with defenselayer \n",
    "# model.body.block1.unit01.relu = QuantizeRelu()\n",
    "# model.body.block1.unit02.relu = QuantizeRelu()\n",
    "# model.body.block1.unit03.relu = QuantizeRelu()\n",
    "\n",
    "# model.body.block2.unit01.relu = QuantizeRelu()\n",
    "# model.body.block2.unit02.relu = QuantizeRelu()\n",
    "# model.body.block2.unit03.relu = QuantizeRelu()\n",
    "# model.body.block2.unit04.relu = QuantizeRelu()\n",
    "\n",
    "# model.body.block3.unit01.relu = QuantizeRelu()\n",
    "# model.body.block3.unit02.relu = QuantizeRelu()\n",
    "# model.body.block3.unit03.relu = QuantizeRelu()\n",
    "# model.body.block3.unit04.relu = QuantizeRelu()\n",
    "# model.body.block3.unit05.relu = QuantizeRelu()\n",
    "# model.body.block3.unit06.relu = QuantizeRelu()\n",
    "\n",
    "model.body.block4.unit01.relu = QuantizeRelu()\n",
    "model.body.block4.unit02.relu = QuantizeRelu()\n",
    "model.body.block4.unit03.relu = QuantizeRelu()\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after changing relu function: 0.93\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9345417925478349"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute_acc(valid_loader, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([40], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [14:59, 899.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Test Accuracy = 1.0\n",
      "tensor([228], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [22:28, 1348.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-79a888e3b60c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            device=device, num_classes=277, save_data=True)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ruofan/PhishIntention/src/adv_attack/attack/Attack.py\u001b[0m in \u001b[0;36mbatch_attack\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mperturbed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'deepfool'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruofan/PhishIntention/src/adv_attack/attack/JSMA.py\u001b[0m in \u001b[0;36mjsma\u001b[0;34m(model, num_classes, image, target, max_iter, clip_min, clip_max)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Calculate Jacobian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mjacobian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# get the highest saliency map's index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ruofan/PhishIntention/src/adv_attack/attack/JSMA.py\u001b[0m in \u001b[0;36mcompute_jacobian\u001b[0;34m(model, num_classes, inputs, output)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mzero_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mjacobian\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mypy37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mypy37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.adv_attack.attack.Attack import *\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "check = adversarial_attack(method='jsma', model=model, dataloader=valid_loader, \n",
    "                           device=device, num_classes=277, save_data=True)\n",
    "\n",
    "acc, _ = check.batch_attack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from advertorch.bpda import BPDAWrapper\n",
    "from advertorch.attacks import LinfPGDAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = KNOWN_MODELS[\"BiT-M-R50x1\"](head_size=180, zero_head=True)\n",
    "model.load_state_dict(torch.load('/home/l/liny/ruofan/phishpedia/siamese/checkpoints/resnetv2_rgb.pth', map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "# BPDA approximation of gradients\n",
    "defense_layer = BPDAWrapper(QuantizeRelu())\n",
    "\n",
    "# replace relu with defenselayer \n",
    "model.body.block1.unit01.relu = defense_layer\n",
    "model.body.block1.unit02.relu = defense_layer\n",
    "model.body.block1.unit03.relu = defense_layer\n",
    "\n",
    "model.body.block2.unit01.relu = defense_layer\n",
    "model.body.block2.unit02.relu = defense_layer\n",
    "model.body.block2.unit03.relu = defense_layer\n",
    "model.body.block2.unit04.relu = defense_layer\n",
    "\n",
    "model.body.block3.unit01.relu = defense_layer\n",
    "model.body.block3.unit02.relu = defense_layer\n",
    "model.body.block3.unit03.relu = defense_layer\n",
    "model.body.block3.unit04.relu = defense_layer\n",
    "model.body.block3.unit05.relu = defense_layer\n",
    "model.body.block3.unit06.relu = defense_layer\n",
    "\n",
    "model.body.block4.unit01.relu = defense_layer\n",
    "model.body.block4.unit02.relu = defense_layer\n",
    "model.body.block4.unit03.relu = defense_layer\n",
    "\n",
    "bpda_adversary = LinfPGDAttack(\n",
    "    model, loss_fn=nn.CrossEntropyLoss(reduction=\"sum\"), eps=0.05,\n",
    "    nb_iter=100, eps_iter=0.005, rand_init=True, clip_min=0.0, clip_max=1.0,\n",
    "    targeted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [21:33<2:30:57, 1293.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 2/8 [44:51<2:12:30, 1325.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 3/8 [1:08:51<1:53:17, 1359.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 4/8 [1:32:18<1:31:34, 1373.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 5/8 [1:56:15<1:09:38, 1392.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 6/8 [2:19:34<46:29, 1394.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 7/8 [2:43:00<23:17, 1397.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9274553571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [2:58:41<00:00, 1340.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9274924471299094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perturb_correct = 0\n",
    "total = 0\n",
    "\n",
    "for cln_data, true_label in tqdm(valid_loader):\n",
    "    cln_data, true_label = cln_data.to(device), true_label.to(device)\n",
    "    bpda_adv = bpda_adversary.perturb(cln_data, true_label)\n",
    "    \n",
    "    logits = model(bpda_adv)\n",
    "    pred_cls = torch.argmax(logits, dim=1)\n",
    "    perturb_correct += torch.sum(torch.eq(pred_cls, true_label)).item()\n",
    "    total += len(true_label)\n",
    "    \n",
    "    print(perturb_correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9274924471299094"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturb_correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.905337361530715"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturb_correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([203])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, 277, (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
