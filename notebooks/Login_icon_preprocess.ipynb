{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import json\n",
    "import funcy\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Rectangle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to transparent logos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree('../datasets/login_icon_transparent')\n",
    "os.makedirs('../datasets/login_icon_transparent', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in os.listdir('../datasets/login_icon/'):\n",
    "    \n",
    "    if not path.endswith('.png'):\n",
    "        im = Image.open('../datasets/login_icon/' + path)\n",
    "        im.save('../datasets/login_icon/' + path.replace('.jpeg', '.png'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in os.listdir('../datasets/login_icon_person/'):\n",
    "    if path.startswith('.'):\n",
    "        continue\n",
    "    if not path.endswith('.png'):\n",
    "        im = Image.open('../datasets/login_icon_person/' + path)\n",
    "        im.save('../datasets/login_icon_person/' + path.replace('.jpeg', '.png'))\n",
    "        os.unlink('../datasets/login_icon_person/' + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in os.listdir('../datasets/login_icon/'):\n",
    "    \n",
    "    if not path.endswith('.png'):\n",
    "        continue\n",
    "        \n",
    "    # load image\n",
    "    img = cv2.imread('../datasets/login_icon/' + path)\n",
    "\n",
    "    # convert to graky\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # threshold input image as mask\n",
    "    mask = cv2.threshold(gray, 250, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # negate mask\n",
    "    mask = 255 - mask\n",
    "\n",
    "    # apply morphology to remove isolated extraneous noise\n",
    "    # use borderconstant of black since foreground touches the edges\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # anti-alias the mask -- blur then stretch\n",
    "    # blur alpha channel\n",
    "    mask = cv2.GaussianBlur(mask, (0,0), sigmaX=2, sigmaY=2, borderType = cv2.BORDER_DEFAULT)\n",
    "\n",
    "    # linear stretch so that 127.5 goes to 0, but 255 stays 255\n",
    "    mask = (2*(mask.astype(np.float32))-255.0).clip(0,255).astype(np.uint8)\n",
    "\n",
    "    # put mask into alpha channel\n",
    "    result = img.copy()\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "    result[:, :, 3] = mask\n",
    "    \n",
    "    # save resulting masked image\n",
    "    cv2.imwrite('../datasets/login_icon_transparent/'+path, result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paste exactly onto the original login button location\n",
    "- Randomly sample screenshots from train_imgs2\n",
    "- Randomly sample icon from login_icon_transparent\n",
    "- Get the annotated login button's position for sampled screenshot $(x1, y1, w, h)$\n",
    "- Resize icon with $width = w, height=h$, might distort the icon\n",
    "- Paste icon onto screenshot $(x1, y1)$\n",
    "- Save new annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    shutil.rmtree('../datasets/login_finder_dataset/train_imgs2_person')\n",
    "except:\n",
    "    pass\n",
    "os.makedirs('../datasets/login_finder_dataset/train_imgs2_person', exist_ok=True)\n",
    "datadict = {'images':[], 'annotations':[], \"categories\": [{'id': 1, 'name':'login'}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/login_finder_dataset/train_coco2.json') as handle:\n",
    "    login_train_coco = json.load(handle) #load gt json file for login button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 0\n",
    "\n",
    "while image_id < 10000:\n",
    "    \n",
    "    # sample a screenshot\n",
    "    img_path_sub = np.random.choice(os.listdir('../datasets/login_finder_dataset/train_imgs2/'))\n",
    "    img_path = os.path.join('../datasets/login_finder_dataset/train_imgs2/', img_path_sub)\n",
    "    \n",
    "    # sample an icon\n",
    "    icon_path_sub = np.random.choice(os.listdir('/home/l/liny/ruofan/PhishIntention/datasets/login_icon_person/'))\n",
    "    icon_path = os.path.join('/home/l/liny/ruofan/PhishIntention/datasets/login_icon_person', icon_path_sub)\n",
    "        \n",
    "    # paste to where the original login button lies\n",
    "    idd = funcy.lfilter(lambda x: x['file_name'] == img_path_sub, login_train_coco[\"images\"])[0]['id']\n",
    "    try:\n",
    "        bbox = funcy.lfilter(lambda x: x['image_id'] == idd, login_train_coco[\"annotations\"])[0]['bbox']\n",
    "    except IndexError:\n",
    "        continue\n",
    "        \n",
    "    # icon resize to original login button's size\n",
    "    resize_shape = [bbox[2], bbox[3]]\n",
    "    if resize_shape[0] <= 0 or resize_shape[1] <= 0:\n",
    "        continue\n",
    "    if max(resize_shape[1]/resize_shape[0], resize_shape[0]/resize_shape[1]) > 2: # aspect ratio too large\n",
    "        continue\n",
    "    if os.path.exists(os.path.join('../datasets/login_finder_dataset/train_imgs2_person/', \n",
    "                              img_path_sub.split('.png')[0] + '_' + icon_path_sub)):\n",
    "        continue # do not overwrite\n",
    "    \n",
    "    # paste icon onto screenshot according to the prob distribution of login button location\n",
    "    im1 = Image.open(img_path)\n",
    "    icon_im = Image.open(icon_path)\n",
    "    icon_im = icon_im.resize((resize_shape[0], resize_shape[1]))\n",
    "    \n",
    "    # convert [0, 1] --> [0, W/H]\n",
    "    random_coordXY = [bbox[0], bbox[1]]\n",
    "    \n",
    "    # paste image\n",
    "    back_im = im1.copy()\n",
    "    back_im.paste(icon_im, (int(random_coordXY[0]), int(random_coordXY[1])))\n",
    "    \n",
    "    # write image into dict[\"images\"]\n",
    "    image = {\n",
    "        \"file_name\": img_path_sub.split('.png')[0] + '_' + icon_path_sub,\n",
    "        \"height\": int(im1.size[1]),\n",
    "        \"width\": int(im1.size[0]),\n",
    "        \"id\": int(image_id),\n",
    "    }\n",
    "    datadict[\"images\"].append(image)\n",
    "    \n",
    "    # write annotations into dict[\"annotations\"]\n",
    "    category_id = 1\n",
    "    id_annot = len(datadict[\"annotations\"]) + 1 #id field must start with 1\n",
    "\n",
    "    ann = {\n",
    "        \"area\": int(resize_shape[0] * resize_shape[1]),\n",
    "        \"image_id\": int(image_id),\n",
    "        \"bbox\": [int(random_coordXY[0]), int(random_coordXY[1]), \n",
    "                 int(resize_shape[0]), int(resize_shape[1])],\n",
    "        \"category_id\": int(category_id),\n",
    "        \"id\": int(id_annot), # id for box, need to be continuous\n",
    "        \"iscrowd\": 0\n",
    "        }\n",
    "\n",
    "    datadict[\"annotations\"].append(ann)\n",
    "        \n",
    "    back_im.save(os.path.join('../datasets/login_finder_dataset/train_imgs2_person/', \n",
    "                              img_path_sub.split('.png')[0] + '_' + icon_path_sub), \n",
    "                 quality=95)\n",
    "    \n",
    "    image_id += 1\n",
    "    \n",
    "    if image_id % 100 == 0:\n",
    "        print(image_id)\n",
    "        with open('../datasets/login_finder_dataset/train_imgs2_person.json', 'wt', encoding='UTF-8') as f:\n",
    "            json.dump(datadict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/login_finder_dataset/train_imgs2_person.json', 'wt', encoding='UTF-8') as f:\n",
    "    json.dump(datadict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../datasets/login_finder_dataset/train_imgs2_augment.json', 'rt', encoding='UTF-8') as f:\n",
    "#     datadict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(os.listdir('../datasets/login_finder_dataset/train_imgs2_person'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('../datasets/login_finder_dataset/train_imgs2_person'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([x in os.listdir('../datasets/login_finder_dataset/train_imgs2_person') for x in funcy.lmap(lambda x: x['file_name'], datadict[\"images\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for j in random.sample(range(10000), 20):\n",
    "    file = funcy.lfilter(lambda x: x['id']==j, datadict[\"images\"])[0]['file_name']\n",
    "    bbox = funcy.lfilter(lambda x: x['image_id']==j, datadict[\"annotations\"])[0]['bbox']\n",
    "    \n",
    "    plt.figure(figsize=(30,30))\n",
    "    plt.imshow(Image.open('../datasets/login_finder_dataset/train_imgs2_person/' + file))\n",
    "    plt.gca().add_patch(Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=5, edgecolor='green', facecolor='none'))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
